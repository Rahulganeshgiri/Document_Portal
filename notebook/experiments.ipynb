{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4137902d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(r\"C:\\Users\\Rahul\\OneDrive\\Desktop\\Document_Portal\\notebook\\interview-questions.pdf\")\n",
    "doc = loader.load()\n",
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09afdc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'interview-questions', 'source': 'C:\\\\Users\\\\Rahul\\\\OneDrive\\\\Desktop\\\\Document_Portal\\\\notebook\\\\interview-questions.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}, page_content='Embeddings,  Vector  DB,  Retrieval,  and  Similarity:  ●  What  embedding  and  vector  DB  did  you  use  and  why?  ●  What  was  the  vector  size  and  what  is  the  impact  of  vector  length?  ●  Which  vector  DB  did  you  use  and  why?  ●  What  are  different  types  of  similarity  search  (cosine,  Euclidean,  Manhattan)  and  when  to  \\nuse\\n \\nwhat?\\n ●  How  to  perform  retrieval  operation?  ●   How  do  you  handle  metadata  in  vector  DB?  ●  What  is  a  vector  DB?  \\nRAG  (Retrieval-Augmented  Generation):  ●   What  is  RAG  architecture?  ●  How  does  RAG  work?  ●   What  are  RAG  failures,  and  how  do  you  evaluate  RAG?  ●   Where  does  the  evaluation  module  sit  in  a  RAG  pipeline?  ●  How  to  design  Multi-modal  RAG?  ●  What  is  RAG  and  Agents?  ●  What  applications  have  you  built  using  RAG,  LangChain,  LangGraph?'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'interview-questions', 'source': 'C:\\\\Users\\\\Rahul\\\\OneDrive\\\\Desktop\\\\Document_Portal\\\\notebook\\\\interview-questions.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}, page_content='Deterministic  &  Guarded  Responses:  ●  How  to  ensure  deterministic  response  in  tightly  coupled  guideline-based  apps?  ●  How  to  define  guardrails  in  LLM  responses?  \\nConversational  AI:  ●  How  is  LLM  chatbot  different  from  normal  chatbot?  ●  How  is  LLM  chatbot  different  from  voice  bots?  ●   How  to  build  full-fledged  conversational  AI  system?  ●  What  is  LangGraph?  ●  What  is  agentic  flow  and  how  to  design  it?    \\nTech  Stack  &  Infra  Integration  Azure  &  Outlook  Flow:  ●  How  system  fetches  PDF  from  Outlook?  ●   Why  use  Azure  Blob  Storage?  ●   What  is  Microsoft  Graph  API?  ●   Role  of  Azure  Functions  or  App  Services?  ●   Why  use  Azure  Cosmos  DB?  ●   What  is  Azure  AI  Search  /  Azure  AI  Studio?  These  are  spot-on  for  cloud-based  GenAI  apps.  Keep  Azure  infra  knowledge  strong.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'interview-questions', 'source': 'C:\\\\Users\\\\Rahul\\\\OneDrive\\\\Desktop\\\\Document_Portal\\\\notebook\\\\interview-questions.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}, page_content='OCR  &  Parsing  ●   How  OCR  works  (including  LLM-based)?  ●   What  happens  after  data  extraction?  ●   How  to  parse  a  table  split  across  multiple  pages?'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'interview-questions', 'source': 'C:\\\\Users\\\\Rahul\\\\OneDrive\\\\Desktop\\\\Document_Portal\\\\notebook\\\\interview-questions.pdf', 'total_pages': 6, 'page': 1, 'page_label': '2'}, page_content='●  What  is  document  parsing  —  how  to  parse  from  documents  and  DBs?  Smart  Tip:  For  multi-page  table  parsing:  discuss  layout-aware  parsing  (like  PDFPlumber,  \\nunstructured.io,\\n \\nlayoutLM)\\n \\n—\\n \\nnot\\n \\njust\\n \\nLLMs\\n.\\n   \\nLLM  Understanding  &  Comparison  ●   What  is  BERT  vs  LLM?  (repeated  but  valid)  ●   How  LLM  is  different  from  BERT?  ●   Token  size  used  in  LLM  input?  ●  Which  LLMs  have  you  used?  ●  Gemini  vs  GPT-4.0?  ●  Deploying  Gemini  4.0-based  RAG  on  Azure/GCP?    \\nModel  Performance,  Accuracy  &  Retraining  ●  ML  metrics  for  classification?  ●   How  to  check  model  accuracy?  ●   What  do  you  do  if  accuracy  reduces?  ●  How  to  retrain  &  split  train-test  data?  Tip:  Be  ready  with  precision,  recall,  F1,  ROC-AUC,  and  confusion  matrix  based  use-cases.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'interview-questions', 'source': 'C:\\\\Users\\\\Rahul\\\\OneDrive\\\\Desktop\\\\Document_Portal\\\\notebook\\\\interview-questions.pdf', 'total_pages': 6, 'page': 1, 'page_label': '2'}, page_content=\"AI  System  Design  /  XAI  /  Production  ●   How  to  manage  concurrency  for  multiple  users?  ●  How  will  you  implement  memory  management?  ●   How  to  manage  cache  /  state?  ●   How  to  implement  XAI  /  Responsible  AI?  ●  How  to  define  &  enforce  guardrails?  ●   All  AI  use  cases  you've  worked  on?   \\nDataset  &  Chunking  \\n●  How  did  you  profile  your  dataset  before  processing  —  number  of  rows,  columns,  data  \\ntypes,\\n \\nmissing\\n \\nvalues?\\n \\n ●  Why  did  you  chunk  a  ~500k  row  dataset  even  though  LLMs  can  handle  small  datasets?  \\n ●  What  chunking  strategies  (fixed,  recursive,  semantic)  did  you  consider,  and  when  is  each  \\nideal?\\n \\n ●  What  impact  does  vector  size/dimension  have  on  retrieval  quality  and  performance?\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'interview-questions', 'source': 'C:\\\\Users\\\\Rahul\\\\OneDrive\\\\Desktop\\\\Document_Portal\\\\notebook\\\\interview-questions.pdf', 'total_pages': 6, 'page': 2, 'page_label': '3'}, page_content='Embeddings,  Vector  DB  &  Retrieval  \\n●  Which  embedding  model  (OpenAI,  BGE,  etc.)  and  vector  DB  (FAISS,  Pinecone,  etc.)  did  \\nyou\\n \\nuse\\n \\nand\\n \\nwhy?\\n \\n ●  What  types  of  vector  stores  exist,  and  when  should  you  use  FAISS,  Pinecone,  Weaviate,  \\nor\\n \\nQdrant?\\n \\n ●  What  indexing  methods  (Flat,  IVF,  PQ,  HNSW)  does  FAISS  support,  and  how  do  they  \\naffect\\n \\nspeed/accuracy?\\n \\n ●  How  are  vectors  stored  internally  in  vector  databases?  \\n ●  How  is  a  vector  retrieved  (via  similarity  search),  and  what  happens  under  the  hood?  \\n ●  How  does  product  quantization  and  inverted  indexing  make  large-scale  search  more  \\nefficient?\\n \\n ●  How  did  you  optimize  search  performance  with  ~800k  rows?  \\n ●  What  similarity  metrics  (cosine,  dot  product,  Euclidean,  Manhattan)  did  you  explore,  and  \\nwhen\\n \\nis\\n \\neach\\n \\nideal?\\n \\n ●  When  would  you  choose  a  managed  vector  DB  like  Pinecone  over  a  local  one  like'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'interview-questions', 'source': 'C:\\\\Users\\\\Rahul\\\\OneDrive\\\\Desktop\\\\Document_Portal\\\\notebook\\\\interview-questions.pdf', 'total_pages': 6, 'page': 2, 'page_label': '3'}, page_content='when\\n \\nis\\n \\neach\\n \\nideal?\\n \\n ●  When  would  you  choose  a  managed  vector  DB  like  Pinecone  over  a  local  one  like  \\nFAISS?\\n \\nRAG  (Retrieval-Augmented  Generation)  \\n●  What  is  RAG  architecture  and  how  did  you  implement  it  in  your  system?  \\n ●  How  do  you  evaluate  and  improve  a  RAG  pipeline  when  responses  are  inaccurate  or  \\nhallucinated?\\n \\n ●  Where  does  the  RAG  evaluation  module  sit,  and  what  metrics  do  you  use  to  validate  \\nresponses?\\n \\n ●  What  different  similarity  search  strategies  are  used  in  RAG,  and  which  is  best  when?  \\n ●  What  is  reranking  (e.g.,  MMR,  cross-encoder),  and  when  is  it  needed  in  RAG?  \\n ●  What  is  agentic  RAG  and  how  does  it  differ  from  classic  retrieval  pipelines?'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'interview-questions', 'source': 'C:\\\\Users\\\\Rahul\\\\OneDrive\\\\Desktop\\\\Document_Portal\\\\notebook\\\\interview-questions.pdf', 'total_pages': 6, 'page': 3, 'page_label': '4'}, page_content='●  What  models/tools  (LangGraph,  LangChain,  FAISS,  OpenAI,  Azure)  did  you  use  to  build  \\nthe\\n \\nRAG\\n \\nsystem?\\n \\n ●  What  is  LangGraph,  and  how  is  it  different  from  LangChain  in  terms  of  agent  \\norchestration?\\n \\nPrompting,  JSON  Output,  LLM  Behavior  \\n●  What  is  the  token  limit  of  GPT-4,  and  how  does  it  affect  chunking  and  prompt  design?  \\n ●  What’s  the  difference  between  zero-shot  and  few-shot  prompting,  and  when  is  each  \\nideal?\\n \\n ●  What  are  the  drawbacks  of  few-shot  prompting  (e.g.,  cost,  prompt  drift,  token  \\nexplosion)?\\n \\n ●  How  do  you  reduce  hallucinations  in  LLMs  when  handling  scientific  or  sensitive  content?  \\n ●  How  do  you  ensure  the  LLM  returns  output  in  valid  JSON  or  structured  format  every  \\ntime?\\n \\n ●  How  do  you  improve  chain-of-thought  and  reasoning  quality  if  LLM  outputs  poor  \\nresponses?'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'interview-questions', 'source': 'C:\\\\Users\\\\Rahul\\\\OneDrive\\\\Desktop\\\\Document_Portal\\\\notebook\\\\interview-questions.pdf', 'total_pages': 6, 'page': 3, 'page_label': '4'}, page_content='time?\\n \\n ●  How  do  you  improve  chain-of-thought  and  reasoning  quality  if  LLM  outputs  poor  \\nresponses?\\n \\n ●  How  many  tokens  were  you  passing  to  the  LLM  on  average,  and  how  did  you  manage  \\ninput\\n \\nlimits?\\n \\n \\nConversational  AI  &  Agent  Design  \\n●  How  is  an  LLM  chatbot  different  from  a  rule-based  or  traditional  chatbot?  \\n ●  How  would  you  implement  role-based  access  (e.g.,  restrict  responses  based  on  \\nemployee\\n \\npay\\n \\ngrade)?\\n \\n ●  Have  you  worked  on  voice  bots,  and  how  do  they  differ  in  architecture  from  chatbots?  \\n ●  How  would  you  design  a  full-fledged  end-to-end  conversational  AI  system  using  \\nLangGraph\\n \\nor\\n \\nLangChain?\\n \\n ●  What  is  an  agentic  flow  and  how  do  you  design  multi-agent  workflows  using  LangGraph?  \\n ●  How  would  you  implement  session  memory  or  chat  history  in  a  multi-turn  chatbot?'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'interview-questions', 'source': 'C:\\\\Users\\\\Rahul\\\\OneDrive\\\\Desktop\\\\Document_Portal\\\\notebook\\\\interview-questions.pdf', 'total_pages': 6, 'page': 4, 'page_label': '5'}, page_content='●  How  do  you  manage  state  and  cache  in  a  high-concurrency  GenAI  application?  \\n ●  How  do  you  scale  your  system  for  many  simultaneous  users  (concurrency  strategy)?  \\nApp  Integration  &  Infra  (Azure,  Email,  Parsing)  \\n●  How  did  your  system  automatically  detect  and  extract  PDF  files  from  Outlook?  \\n ●  Why  did  you  use  Azure  Blob  Storage  —  what  benefit  did  it  bring  to  your  pipeline?  \\n ●  What  does  Microsoft  Graph  API  do  in  your  architecture?  \\n ●  What’s  the  role  of  Azure  Functions  or  App  Services  in  your  RAG-based  solution?  \\n ●  What  is  Azure  AI  Search  and  how  does  it  work  with  vector-based  search?  \\n ●  Why  did  you  use  Azure  Cosmos  DB  instead  of  MongoDB  or  SQL?  \\n ●  How  did  you  parse  multi-page  tables  in  DOCX/PDF  files  (cost-efficient  +  accurate)?  \\n ●  What  steps  did  your  system  follow  after  extracting  data  via  OCR  (structured  parsing)?'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'interview-questions', 'source': 'C:\\\\Users\\\\Rahul\\\\OneDrive\\\\Desktop\\\\Document_Portal\\\\notebook\\\\interview-questions.pdf', 'total_pages': 6, 'page': 4, 'page_label': '5'}, page_content='●  What  steps  did  your  system  follow  after  extracting  data  via  OCR  (structured  parsing)?  \\n \\nML  Model  Metrics,  Accuracy  &  Retraining  \\n●  What  classification  metrics  (accuracy,  precision,  recall,  F1)  did  you  use  and  why?  \\n ●  If  model  accuracy  dropped,  how  did  you  debug  and  improve  the  pipeline?  \\n ●  How  do  you  retrain  an  ML  model,  and  how  do  you  manage  train/test  split  to  avoid  \\nleakage?\\n \\n ●  How  do  you  check  and  measure  model  accuracy,  both  for  LLMs  and  ML  models?  \\n \\nData  Structures  &  Algorithms  (DSA)  \\n●  What  are  the  best  and  worst-case  time  complexities  for  common  list  operations?  \\n ●  What’s  the  time  complexity  for  Python  list  operations  like  append,  insert,  pop,  etc.?  \\n ●  Which  is  faster  —  list  or  dictionary  —  and  in  what  scenarios?'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'interview-questions', 'source': 'C:\\\\Users\\\\Rahul\\\\OneDrive\\\\Desktop\\\\Document_Portal\\\\notebook\\\\interview-questions.pdf', 'total_pages': 6, 'page': 5, 'page_label': '6'}, page_content='GenAI  Project  Discussion  \\n●  Walk  me  through  your  latest  Generative  AI  project  (business  problem,  technical  flow,  \\noutcomes).\\n \\n ●  What  LLM  models,  vector  DBs,  tools,  and  cloud  services  did  you  use?  \\n ●  How  did  you  implement  Human-in-the-Loop  in  your  system  to  improve  quality  and  trust?  \\n ●  How  did  you  integrate  Responsible  AI  principles  (e.g.,  explainability,  fairness,  scientific  \\nvalidity)?\\n \\n ●  How  did  you  extract  structured  data  from  unstructured  documents  (e.g.,  research  \\nPDFs)?\\n \\n ●  What  was  the  structure  of  the  tech  team,  and  what  was  your  exact  role?  \\n ●  How  did  your  pipeline  handle  scale,  latency,  and  large  document  parsing?  \\nBehavioral  +  Guesstimate  \\n●  Guesstimate:  What  is  Netflix’s  annual  revenue?  (Show  step-by-step  thinking:  users  ×  \\nARPU)\\n \\n ●  If  we  call  your  manager  right  now,  what  are  3  strengths  and  3  improvement  areas  they’d  \\nshare?')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(doc)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06013b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "LANGCHAIN_API_KEY=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "Gemini_API_KEY=os.getenv(\"Gemini_API_KEY\")\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "HuggingFace_API_KEY=os.getenv(\"HuggingFace_API_KEY\")\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec030406",
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDefaultCredentialsError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GoogleGenerativeAIEmbeddings\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m embeddings = \u001b[43mGoogleGenerativeAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels/embedding-001\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAIzaSyCvdTpL-gPh9xnnsweFmr9cxtbyvThY9nI\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rahul\\OneDrive\\Desktop\\Document_Portal\\env\\Lib\\site-packages\\langchain_google_genai\\embeddings.py:103\u001b[39m, in \u001b[36mGoogleGenerativeAIEmbeddings.validate_environment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28mself\u001b[39m.model.startswith(prefix) \u001b[38;5;28;01mfor\u001b[39;00m prefix \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mmodels/\u001b[39m\u001b[33m\"\u001b[39m,)):\n\u001b[32m    101\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodels/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.model\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28mself\u001b[39m.client = \u001b[43mbuild_generative_service\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgoogle_api_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[38;5;28mself\u001b[39m.async_client = build_generative_async_service(\n\u001b[32m    111\u001b[39m     credentials=\u001b[38;5;28mself\u001b[39m.credentials,\n\u001b[32m    112\u001b[39m     api_key=google_api_key,\n\u001b[32m   (...)\u001b[39m\u001b[32m    115\u001b[39m     transport=\u001b[38;5;28mself\u001b[39m.transport,\n\u001b[32m    116\u001b[39m )\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rahul\\OneDrive\\Desktop\\Document_Portal\\env\\Lib\\site-packages\\langchain_google_genai\\_genai_extension.py:276\u001b[39m, in \u001b[36mbuild_generative_service\u001b[39m\u001b[34m(credentials, api_key, client_options, client_info, transport)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_generative_service\u001b[39m(\n\u001b[32m    263\u001b[39m     credentials: Optional[credentials.Credentials] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    264\u001b[39m     api_key: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m     transport: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    268\u001b[39m ) -> v1betaGenerativeServiceClient:\n\u001b[32m    269\u001b[39m     config = _prepare_config(\n\u001b[32m    270\u001b[39m         credentials=credentials,\n\u001b[32m    271\u001b[39m         api_key=api_key,\n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m         client_info=client_info,\n\u001b[32m    275\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mv1betaGenerativeServiceClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rahul\\OneDrive\\Desktop\\Document_Portal\\env\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:697\u001b[39m, in \u001b[36mGenerativeServiceClient.__init__\u001b[39m\u001b[34m(self, credentials, transport, client_options, client_info)\u001b[39m\n\u001b[32m    688\u001b[39m     transport_init: Union[\n\u001b[32m    689\u001b[39m         Type[GenerativeServiceTransport],\n\u001b[32m    690\u001b[39m         Callable[..., GenerativeServiceTransport],\n\u001b[32m   (...)\u001b[39m\u001b[32m    694\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m cast(Callable[..., GenerativeServiceTransport], transport)\n\u001b[32m    695\u001b[39m     )\n\u001b[32m    696\u001b[39m     \u001b[38;5;66;03m# initialize with the provided callable or the passed in class\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m697\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport = \u001b[43mtransport_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient_cert_source_for_mtls\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_cert_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m        \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33masync\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m._transport):\n\u001b[32m    710\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m CLIENT_LOGGING_SUPPORTED \u001b[38;5;129;01mand\u001b[39;00m _LOGGER.isEnabledFor(\n\u001b[32m    711\u001b[39m         std_logging.DEBUG\n\u001b[32m    712\u001b[39m     ):  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rahul\\OneDrive\\Desktop\\Document_Portal\\env\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\transports\\grpc.py:234\u001b[39m, in \u001b[36mGenerativeServiceGrpcTransport.__init__\u001b[39m\u001b[34m(self, host, credentials, credentials_file, scopes, channel, api_mtls_endpoint, client_cert_source, ssl_channel_credentials, client_cert_source_for_mtls, quota_project_id, client_info, always_use_jwt_access, api_audience)\u001b[39m\n\u001b[32m    229\u001b[39m             \u001b[38;5;28mself\u001b[39m._ssl_channel_credentials = grpc.ssl_channel_credentials(\n\u001b[32m    230\u001b[39m                 certificate_chain=cert, private_key=key\n\u001b[32m    231\u001b[39m             )\n\u001b[32m    233\u001b[39m \u001b[38;5;66;03m# The base transport sets the host, credentials and scopes\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m=\u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._grpc_channel:\n\u001b[32m    246\u001b[39m     \u001b[38;5;66;03m# initialize with the provided callable or the default channel\u001b[39;00m\n\u001b[32m    247\u001b[39m     channel_init = channel \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).create_channel\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rahul\\OneDrive\\Desktop\\Document_Portal\\env\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\transports\\base.py:100\u001b[39m, in \u001b[36mGenerativeServiceTransport.__init__\u001b[39m\u001b[34m(self, host, credentials, credentials_file, scopes, quota_project_id, client_info, always_use_jwt_access, api_audience, **kwargs)\u001b[39m\n\u001b[32m     96\u001b[39m     credentials, _ = google.auth.load_credentials_from_file(\n\u001b[32m     97\u001b[39m         credentials_file, **scopes_kwargs, quota_project_id=quota_project_id\n\u001b[32m     98\u001b[39m     )\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ignore_credentials:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     credentials, _ = \u001b[43mgoogle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mscopes_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquota_project_id\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m     \u001b[38;5;66;03m# Don't apply audience if the credentials file passed from user.\u001b[39;00m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(credentials, \u001b[33m\"\u001b[39m\u001b[33mwith_gdch_audience\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Rahul\\OneDrive\\Desktop\\Document_Portal\\env\\Lib\\site-packages\\google\\auth\\_default.py:739\u001b[39m, in \u001b[36mdefault\u001b[39m\u001b[34m(scopes, request, quota_project_id, default_scopes)\u001b[39m\n\u001b[32m    731\u001b[39m             _LOGGER.warning(\n\u001b[32m    732\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mNo project ID could be determined. Consider running \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    733\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    734\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33menvironment variable\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    735\u001b[39m                 environment_vars.PROJECT,\n\u001b[32m    736\u001b[39m             )\n\u001b[32m    737\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[32m--> \u001b[39m\u001b[32m739\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[31mDefaultCredentialsError\u001b[39m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information."
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ccef1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d48f3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
